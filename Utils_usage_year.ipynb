{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1 #null before 2752\n",
      "After:  1938\n",
      "Level 2 #null before 1938\n",
      "After:  1254\n",
      "Level 3 #null before 1254\n",
      "After:  912\n",
      "Level 4 #null before 912\n",
      "After:  570\n"
     ]
    }
   ],
   "source": [
    "#load the historial data in 2017 and 2018\n",
    "#here I use data from 2017-02-14-2017-07-01 and 2018-02-01 2018-04-01\n",
    "aq_old,ob_old,grid_old = load_old_all(start_17='2017-02-14 00:00:00',end_17='2017-06-01 00:00:00',start_18='2018-02-01 00:00:00',end_18='2018-04-01 00:00:00')\n",
    "\n",
    "#prepare weather data\n",
    "weather_old_all = pd.concat([ob_old,grid_old]).reset_index()\n",
    "weather_old_all = clean_weather(weather_old_all)\n",
    "weather_old_all = weather_old_all.drop(['latitude','longitude'],axis=1)\n",
    "\n",
    "#add time columns to airQuality data\n",
    "#levels is the number of nearest weather station to search\n",
    "#time_column is the name of the time column\n",
    "aq_old_all = fill_weather_gap(aq_df=aq_old,weather_df=weather_old_all,levels = 5,time_column = 'utc_time')\n",
    "\n",
    "aq_old_all['timestamp'] = pd.to_datetime(aq_old_all['utc_time'])\n",
    "aq_old_all['year'] = aq_old_all['timestamp'].dt.year\n",
    "aq_old_all['month'] = aq_old_all['timestamp'].dt.month\n",
    "aq_old_all['day'] = aq_old_all['timestamp'].dt.day\n",
    "aq_old_all['hour'] = aq_old_all['timestamp'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124719 entries, 0 to 923\n",
      "Data columns (total 21 columns):\n",
      "utc_time           124719 non-null object\n",
      "PM2.5              118474 non-null float64\n",
      "PM10               95007 non-null float64\n",
      "NO2                119133 non-null float64\n",
      "CO                 106258 non-null float64\n",
      "O3                 118450 non-null float64\n",
      "SO2                119213 non-null float64\n",
      "longitude          124719 non-null float64\n",
      "latitude           124719 non-null float64\n",
      "station_type_id    124719 non-null int64\n",
      "dist               124719 non-null float64\n",
      "w_end              124719 non-null object\n",
      "humidity           124149 non-null float64\n",
      "pressure           124149 non-null float64\n",
      "temperature        124149 non-null float64\n",
      "station_id         124719 non-null object\n",
      "timestamp          124719 non-null datetime64[ns]\n",
      "year               124719 non-null int64\n",
      "month              124719 non-null int64\n",
      "day                124719 non-null int64\n",
      "hour               124719 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(12), int64(5), object(3)\n",
      "memory usage: 20.9+ MB\n"
     ]
    }
   ],
   "source": [
    "aq_old_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO:predict aq loss value\n",
    "aq_old_all = aq_old_all.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aq_2017 = aq_old_all.loc[aq_old_all.year == 2017]\n",
    "aq_2018 = aq_old_all.loc[aq_old_all.year == 2018]\n",
    "time_columns = ['year','month','day','hour']\n",
    "attrs_to_predict = ['PM2.5', 'PM10', 'O3']\n",
    "timestamp_column_name = 'utc_time'\n",
    "\n",
    "#result will be numpy array in the format (station_id,station_type_id,time_columns,historical_data-> 24*7*3 * 3,to_be_predicted_values)\n",
    "data_2017 = get_raw_train_test_data(aq_2017,attrs_to_predict,time_columns,timestamp_column_name,24*7*3)\n",
    "data_2018 = get_raw_train_test_data(aq_2018,attrs_to_predict,time_columns,timestamp_column_name,24*7*3)\n",
    "\n",
    "data_2017_2018_raw = np.array(data_2017+data_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store the file for quick load\n",
    "np.save('/mnt/disks/bdt/data_2017_2018_before_extract_v1.npy',data_2017_2018_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from the raw historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2017_2018_raw = np.load('/mnt/disks/bdt/data_2017_2018_before_extract_v1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the features and labels from raw historical data\n",
    "#attr is the attribute we need to predict,it can be 'PM2.5','PM10','O3'\n",
    "#length is the window size of the number of historical data we used, here we used the previous 3 weeks to predict the value in next 49 hours\n",
    "X_raw,y_raw = split_features_labels(data = data_2017_2018_raw,attr = 'PM2.5',length = 24*7*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/mnt/disks/bdt/2017_2018_X_v1.npy',X_raw)\n",
    "np.save('/mnt/disks/bdt/2017_2018_y_v1.npy',y_raw)\n",
    "\n",
    "X_raw = X_raw.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86079, 342)\n",
      "(86079, 48)\n"
     ]
    }
   ],
   "source": [
    "print(X_raw.shape)\n",
    "print(y_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到y_raw有48行，他是对应的48小时我们要predict的数据，不能直接放到model去train，需要onehot要预测的是后几个小时\n",
    "X_raw已经含有前三周的一些特征，包括最后一周的原始数据，三周内每一天的statistical 值[min max mean median var],每一周statistical的值,holiday feature 的值->[是否放假第一天，是否放假前一天，是否放假最后一天，是否上班第一天]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#这是用来选择部分站点的，因为feature前几行是站点的one_hot信息\n",
    "def select_part_of_stations(train_x,train_y,station_num):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i in range(station_num):\n",
    "        station_x = train_x[np.where(train_x[:,i] == 1)]\n",
    "        station_y = train_y[np.where(train_x[:,i] == 1)].reshape(-1,1)\n",
    "        x_list.append(station_x)\n",
    "        y_list.append(station_y)\n",
    "    return np.vstack(x_list),np.vstack(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把X_raw,y_ra 变成可以train的数据： one hot要preddict的value是48小时的哪一个(用48行的diag matrix), 复制48次X_raw 的每一行，把y_raw transpose\n",
    "#一下变成48行\n",
    "\n",
    "#我暂时内存不够，不能一次调用全部，只能拿部分站点出来做调参\n",
    "train_2017_2018 = get_train_data_final(X_raw,y_raw)\n",
    "train_x = train_data_2017_2018[:,:-1]\n",
    "train_y = train_data_2017_2018[:,-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
